{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52466f56-24a2-488d-99bd-462156760dd0",
   "metadata": {},
   "source": [
    "# Exercise 1 - Signal processing\n",
    "\n",
    "In this practical we will use a signal processing based workflow in phenopype to segment some butterflies of the genus Junonia. The images stem from museum collections and are highly standardized, therefore signal processing will work well for us.\n",
    "\n",
    "<center><img src=../assets/butterfly-example.jpg width=\"500\" ></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9302e8-c7dd-419a-a43d-5693c2a28b41",
   "metadata": {},
   "source": [
    "We start by importing phenopype (www.phenopype.org). Here we also set our project working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a673b-8631-47a5-90a2-dd2e08bfa1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"D:\\git-repos\\mluerig\\phenomics-workshop-aussois\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03940e28-02f0-4ede-903e-5716797ba44e",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "NOTE: This assumes that you <a href=\"https://www.dropbox.com/scl/fo/ohva31yvrszje221ratpg/ANQdv85xdhkgkwctR5es5OA?rlkey=4kvcsjmlndms70otqsr8ui06y&dl=0\" target=\"_blank\">downloaded the data-archive</a> from dropbox and placed the \"data_raw\" folder in the github-repo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984eaced-2ff5-4356-a6ec-1f4cd5817e51",
   "metadata": {},
   "source": [
    "## Python mode\n",
    "\n",
    "Good for self-education, prototyping, custom workflows, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820403da-6eba-4e95-91c5-3781f9c09f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load image\n",
    "img = pp.load_image(r\"data_raw\\images_set1\\junonia_coenia\\a7d622d7-b4ff-476c-b61f-2229490aa713_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff377ba-dd85-4465-8427-8b4a2443468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show image (close with enter)\n",
    "pp.show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93121f3-6ef2-4e23-ba57-0edf9b5f387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a mask\n",
    "annotations = pp.preprocessing.create_mask(img)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a79e6-1de9-4ea8-b951-9e1d551c9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select gray channel (many if not most SP algorithms need single channel)\n",
    "img_gray = pp.preprocessing.decompose_image(img, channel=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e843ba-bc65-402a-ae78-e7c70f1612f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## threshold algorithm to produce binary mask\n",
    "img_mask = pp.segmentation.threshold(img_gray, method=\"binary\", annotations=annotations)\n",
    "pp.show_image(img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d4f72-39fe-4bd0-8d8f-3f533e98c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## what did we do here:\n",
    "hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(hist, color='black', linewidth=1.5)\n",
    "plt.axvline(x=127, color='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a9a83-c884-473d-9c39-6295fbca641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bad choice of cutoff value\n",
    "img_mask = pp.segmentation.threshold(img_gray, method=\"binary\", value=100, annotations=annotations)\n",
    "pp.show_image(img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03267e4c-52c5-45ce-8476-a78841101299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## better choice for cutoff\n",
    "img_mask = pp.segmentation.threshold(img_gray, method=\"binary\", value=160, annotations=annotations)\n",
    "pp.show_image(img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9d51c-6712-4616-9c1d-ed0080578e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blurred = pp.preprocessing.blur(img, kernel_size=5)\n",
    "img_mask = pp.segmentation.threshold(img_blurred, method=\"binary\", value=160, annotations=annotations)\n",
    "pp.show_image(img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450910e-e6e6-4d6c-9ff3-16d7759d3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(hist, color='black', linewidth=1.5)\n",
    "plt.axvline(x=160, color='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d181a-46bf-4144-955e-0ea83971f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect contour in binary image - spits out a json file\n",
    "pp.segmentation.detect_contour(img_mask, annotations=annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae127e4-8f3f-4376-bb92-9269d26424b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter!\n",
    "annotations = pp.segmentation.detect_contour(img_mask, annotations=annotations, min_area=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efaed4-1580-40de-be8e-eba5e8f2e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's measure shape traits\n",
    "annotations = pp.measurement.compute_shape_features(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5280e-a150-418a-b9aa-ca85d13ae506",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's measure texture traits (pyradiomics)\n",
    "annotations = pp.measurement.compute_texture_features(img, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be09e7d-fa70-4063-92e7-b0e274243efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a canvas and draw annotations as image elements\n",
    "canvas = pp.visualization.select_canvas(img)\n",
    "canvas = pp.visualization.draw_mask(canvas, annotations, line_colour=\"blue\")\n",
    "canvas = pp.visualization.draw_contour(canvas, annotations)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4278a2-c118-4046-9005-b839e4cb85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export canvas, and annotations as json and csv (csv needs image name)\n",
    "pp.export.save_canvas(canvas, dir_path=\"phenopype\")\n",
    "pp.export.save_annotation(annotations, file_name=r\"annotations1.json\", dir_path=\"phenopype\")\n",
    "pp.export.export_csv(annotations, image_name=\"a7d622d7-b4ff-476c-b61f-2229490aa713_1.jpg\", dir_path=\"phenopype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68322aaa-fc1b-4b52-8378-e2a7292bb440",
   "metadata": {},
   "source": [
    "## Using the interactive workflow\n",
    "\n",
    "Here, instead of writing down our analysis as a sequence of Python code, as we did in the low throughput workflow, we supply the same functions through a configuration file in human readable YAML format. This file can then be loaded by phenopypeâ€™s Pype class, which initiates the analysis by triggering three actions:\n",
    "\n",
    "1. open the YAML configuration file in the default OS text editor\n",
    "2. parse the contained functions and execute them in the sequence\n",
    "3. open a HighGUI window showing the processed image, updates with every step\n",
    "\n",
    "After an iteration of all steps, users can evaluate the results and decide to modify the opened configuration file (e.g. either change function parameters or add new functions), and run Pype again (by saving the changes), or to terminate the Pype-run and save all results to the root folder of the image (using Ctrl+Enter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162f28e-86d0-45fc-b99b-7cb1902ee775",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.Pype(image_path=r\"data_raw\\images_set1\\junonia_coenia\\a7d622d7-b4ff-476c-b61f-2229490aa713_1.jpg\", \n",
    "        tag=\"01\", config_path=\"templates/01-thresholding.yaml\", dir_path=\"phenopype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0301f6-1200-4699-a1df-1c5e2d2c1645",
   "metadata": {},
   "source": [
    "## Using projects\n",
    "Now that we know what happens behind the scences move on and make a phenopype project to work . If the downloaded git repo is my project main directory, then I would store different phenopype projects in a subfolder - let's name it \"phenopype\" and the project \"project1\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329b3b8-a092-4b59-9b87-a1edf143cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pp.Project(\"phenopype/project1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db907cb-7d12-46ec-8ef0-65fb88805953",
   "metadata": {},
   "source": [
    "Next we import images to the project: first we use `images_set1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266670b-2d8e-4c1d-b4b6-7f4cccf9e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.add_files(\"data_raw\\images_set1\",recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3ea73-d5bd-4779-acdf-1ef90321366d",
   "metadata": {},
   "source": [
    "Next we use `add_config`add configuration files to each project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f713c6-17d0-419b-9578-488f5202b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.add_config(tag=\"01\", template_path = \"templates/01-thresholding.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e13b4-82d8-4808-9f77-98d1751eddbe",
   "metadata": {},
   "source": [
    "Finally, we go through all directories using a simple for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075d919-f148-4bf5-be22-94a6c9cd12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in proj.dir_paths:\n",
    "    p1 = pp.Pype(path, tag=\"01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6eeec-e3b8-47c9-a54b-6f4681f1c593",
   "metadata": {},
   "source": [
    "If we need to modify a config and adjust it for all, we can do so here by setting overwrite=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f57bb7-a550-4a3e-8a71-21fd3fe19883",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.add_config(tag=\"01\", template_path = \"templates/01-thresholding.yaml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27a9f9-a37d-460c-8764-48465d54019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in proj.dir_paths:\n",
    "    p1 = pp.Pype(path, tag=\"01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645216f-9102-4915-9237-302bb995cf67",
   "metadata": {},
   "source": [
    "## Using different config files with \"tag\"\n",
    "\n",
    "To add different config files to the same project use different tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a79c1-5ac0-4fc2-85e4-619bfacf7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.add_config(tag=\"02\", template_path = \"templates/02-thresholding.yaml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09d0e0-4103-41ae-bdfb-2f8b3a2f8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in proj.dir_paths:\n",
    "    p1 = pp.Pype(path, tag=\"02\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
